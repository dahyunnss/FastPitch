{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Processing seed 0\n",
      "[INFO] Seed 0:\n",
      "Train set size: 7860\n",
      "Validation set size: 2616\n",
      "Test set size: 2620\n",
      "\n",
      "\n",
      "[INFO] Processing seed 1\n",
      "[INFO] Seed 1:\n",
      "Train set size: 7860\n",
      "Validation set size: 2616\n",
      "Test set size: 2620\n",
      "\n",
      "\n",
      "[INFO] Processing seed 2\n",
      "[INFO] Seed 2:\n",
      "Train set size: 7860\n",
      "Validation set size: 2616\n",
      "Test set size: 2620\n",
      "\n",
      "\n",
      "[INFO] Processing seed 3\n",
      "[INFO] Seed 3:\n",
      "Train set size: 7860\n",
      "Validation set size: 2616\n",
      "Test set size: 2620\n",
      "\n",
      "\n",
      "[INFO] Processing seed 4\n",
      "[INFO] Seed 4:\n",
      "Train set size: 7860\n",
      "Validation set size: 2616\n",
      "Test set size: 2620\n",
      "\n",
      "\n",
      "[INFO] Processing seed 5\n",
      "[INFO] Seed 5:\n",
      "Train set size: 7860\n",
      "Validation set size: 2616\n",
      "Test set size: 2620\n",
      "\n",
      "\n",
      "[INFO] Processing seed 6\n",
      "[INFO] Seed 6:\n",
      "Train set size: 7860\n",
      "Validation set size: 2616\n",
      "Test set size: 2620\n",
      "\n",
      "\n",
      "[INFO] Processing seed 7\n",
      "[INFO] Seed 7:\n",
      "Train set size: 7860\n",
      "Validation set size: 2616\n",
      "Test set size: 2620\n",
      "\n",
      "\n",
      "[INFO] Processing seed 8\n",
      "[INFO] Seed 8:\n",
      "Train set size: 7860\n",
      "Validation set size: 2616\n",
      "Test set size: 2620\n",
      "\n",
      "\n",
      "[INFO] Processing seed 9\n",
      "[INFO] Seed 9:\n",
      "Train set size: 7860\n",
      "Validation set size: 2616\n",
      "Test set size: 2620\n",
      "\n",
      "Data split and saved for all seeds.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "# 경로 및 파일 설정\n",
    "input_file = '/userHome/userhome2/dahyun/DeepLearningExamples/PyTorch/SpeechSynthesis/FastPitch/LJSpeech-1.1/ljs_audio_pitch_text_all.txt'\n",
    "output_dir = '/userHome/userhome2/dahyun/DeepLearningExamples/PyTorch/SpeechSynthesis/FastPitch/LJSpeech-1.1/seed_all'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# 데이터셋 로드 (공백 및 빈 줄 제거)\n",
    "with open(input_file, 'r') as f:\n",
    "    data = [line.strip() for line in f.readlines() if line.strip()]  # 공백 또는 빈 줄을 제거\n",
    "\n",
    "# 시드별 데이터셋 분할 함수\n",
    "def split_data(seed, data):\n",
    "    random.seed(seed)\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    # 고정된 크기 설정\n",
    "    test_size = 2620  # 고정된 test 크기\n",
    "    train_size = 7860  # 고정된 train 크기\n",
    "    val_size = 2620    # 고정된 validation 크기\n",
    "    \n",
    "    # test 데이터를 정확히 2620개로 떼어냄\n",
    "    test_data = data[:test_size]\n",
    "    \n",
    "    # 남은 데이터를 train + validation으로 분할\n",
    "    train_val_data = data[test_size:]\n",
    "    \n",
    "    # train 데이터를 7860개, validation 데이터를 2620개로 정확히 분할\n",
    "    train_data = train_val_data[:train_size]\n",
    "    val_data = train_val_data[train_size:train_size + val_size]\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# 시드별로 데이터셋 분할 및 폴더에 저장\n",
    "for seed in range(10):\n",
    "    print(f\"\\n[INFO] Processing seed {seed}\")\n",
    "    train, val, test = split_data(seed, data)\n",
    "    \n",
    "    \n",
    "    # 파일 경로 설정\n",
    "    train_file = os.path.join(output_dir, f'train_seed_{seed}.txt')\n",
    "    val_file = os.path.join(output_dir, f'val_seed_{seed}.txt')\n",
    "    test_file = os.path.join(output_dir, f'test_seed_{seed}.txt')\n",
    "    \n",
    "    # 파일에 train, val, test 데이터 저장\n",
    "    with open(train_file, 'w') as f:\n",
    "        f.write(\"\\n\".join(train) + \"\\n\")  # 마지막에 공백 줄이 없도록 처리\n",
    "    with open(val_file, 'w') as f:\n",
    "        f.write(\"\\n\".join(val) + \"\\n\")\n",
    "    with open(test_file, 'w') as f:\n",
    "        f.write(\"\\n\".join(test) + \"\\n\")\n",
    "    \n",
    "    # 각 데이터셋의 길이 출력\n",
    "    print(f\"[INFO] Seed {seed}:\")\n",
    "    print(f\"Train set size: {len(train)}\")\n",
    "    print(f\"Validation set size: {len(val)}\")\n",
    "    print(f\"Test set size: {len(test)}\\n\")\n",
    "\n",
    "print(\"Data split and saved for all seeds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 버전: 1.26.4\n",
      "scipy 버전: 1.13.1\n",
      "pyworld 버전: 0.3.4\n",
      "scikit-learn 버전: 1.5.2\n",
      "matplotlib 버전: 3.9.2\n",
      "python_speech_features 버전: <module 'python_speech_features' from '/userHome/userhome2/dahyun/miniconda3/envs/Fastpitch/lib/python3.9/site-packages/python_speech_features/__init__.py'>\n",
      "torch 버전: 1.12.0+cu116\n",
      "apex 버전: <module 'apex' (namespace)>\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import pyworld\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import python_speech_features\n",
    "import torch\n",
    "import apex\n",
    "\n",
    "print(\"numpy 버전:\", numpy.__version__)\n",
    "print(\"scipy 버전:\", scipy.__version__)\n",
    "print(\"pyworld 버전:\", pyworld.__version__)\n",
    "print(\"scikit-learn 버전:\", sklearn.__version__)\n",
    "print(\"matplotlib 버전:\", matplotlib.__version__)\n",
    "print(\"python_speech_features 버전:\", python_speech_features)\n",
    "print(\"torch 버전:\", torch.__version__)\n",
    "print(\"apex 버전:\", apex)\n",
    "#python -c \"import amp_C\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch CUDA Version: 11.6\n",
      "Number of CUDA Devices: 4\n",
      "Device 0: NVIDIA GeForce RTX 3090\n",
      "Device 1: NVIDIA GeForce RTX 3090\n",
      "Device 2: NVIDIA GeForce RTX 3090\n",
      "Device 3: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def check_pytorch_cuda():\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"PyTorch CUDA Version: {torch.version.cuda}\")\n",
    "        print(f\"Number of CUDA Devices: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    else:\n",
    "        print(\"CUDA is not available in PyTorch.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_pytorch_cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'amp_C'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mamp_C\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mApex 설치 성공\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'amp_C'"
     ]
    }
   ],
   "source": [
    "import amp_C\n",
    "\n",
    "print('Apex 설치 성공')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PyTorch 정보 ===\n",
      "PyTorch 버전: 1.12.0+cu116\n",
      "PyTorch CUDA 지원: 예\n",
      "PyTorch CUDA 버전: 11.6\n",
      "사용 가능한 CUDA 디바이스 수: 4\n",
      "  디바이스 0: NVIDIA GeForce RTX 3090\n",
      "  디바이스 1: NVIDIA GeForce RTX 3090\n",
      "  디바이스 2: NVIDIA GeForce RTX 3090\n",
      "  디바이스 3: NVIDIA GeForce RTX 3090\n",
      "\n",
      "=== 시스템 CUDA 컴파일러 버전 (nvcc) ===\n",
      "nvcc가 설치되어 있지 않거나 PATH에 없습니다.\n",
      "\n",
      "=== NVIDIA 드라이버 버전 (nvidia-smi) ===\n",
      "NVIDIA 드라이버 버전: 550.54\n",
      "\n",
      "=== PyTorch와 시스템 CUDA 버전 호환성 ===\n",
      "nvcc가 설치되어 있지 않거나 PATH에 없습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "def get_pytorch_info():\n",
    "    print(\"=== PyTorch 정보 ===\")\n",
    "    print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"PyTorch CUDA 지원: 예\")\n",
    "        print(f\"PyTorch CUDA 버전: {torch.version.cuda}\")\n",
    "        print(f\"사용 가능한 CUDA 디바이스 수: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"  디바이스 {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    else:\n",
    "        print(\"PyTorch CUDA 지원: 아니오\")\n",
    "    print()\n",
    "\n",
    "def get_system_cuda_version():\n",
    "    print(\"=== 시스템 CUDA 컴파일러 버전 (nvcc) ===\")\n",
    "    try:\n",
    "        result = subprocess.run(['nvcc', '--version'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, check=True)\n",
    "        nvcc_output = result.stdout\n",
    "        match = re.search(r'release (\\d+\\.\\d+)', nvcc_output)\n",
    "        if match:\n",
    "            nvcc_version = match.group(1)\n",
    "            print(f\"nvcc CUDA 버전: {nvcc_version}\")\n",
    "        else:\n",
    "            print(\"nvcc 출력에서 CUDA 버전을 파싱할 수 없습니다.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"nvcc가 설치되어 있지 않거나 PATH에 없습니다.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"nvcc 실행 중 오류 발생: {e}\")\n",
    "    print()\n",
    "\n",
    "def get_nvidia_driver_version():\n",
    "    print(\"=== NVIDIA 드라이버 버전 (nvidia-smi) ===\")\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, check=True)\n",
    "        nvidia_smi_output = result.stdout\n",
    "        match = re.search(r'Driver Version:\\s+(\\d+\\.\\d+)', nvidia_smi_output)\n",
    "        if match:\n",
    "            driver_version = match.group(1)\n",
    "            print(f\"NVIDIA 드라이버 버전: {driver_version}\")\n",
    "        else:\n",
    "            print(\"nvidia-smi 출력에서 드라이버 버전을 파싱할 수 없습니다.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"nvidia-smi가 설치되어 있지 않거나 PATH에 없습니다.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"nvidia-smi 실행 중 오류 발생: {e}\")\n",
    "    print()\n",
    "\n",
    "def check_compatibility():\n",
    "    print(\"=== PyTorch와 시스템 CUDA 버전 호환성 ===\")\n",
    "    pytorch_cuda = torch.version.cuda\n",
    "    try:\n",
    "        result = subprocess.run(['nvcc', '--version'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, check=True)\n",
    "        nvcc_output = result.stdout\n",
    "        match = re.search(r'release (\\d+\\.\\d+)', nvcc_output)\n",
    "        if match:\n",
    "            system_cuda = match.group(1)\n",
    "            if pytorch_cuda and system_cuda.startswith(pytorch_cuda):\n",
    "                print(f\"호환성: 예 (PyTorch CUDA 버전 {pytorch_cuda}과 시스템 CUDA 버전 {system_cuda} 일치)\")\n",
    "            else:\n",
    "                print(f\"호환성: 아니오 (PyTorch CUDA 버전 {pytorch_cuda}과 시스템 CUDA 버전 {system_cuda} 불일치)\")\n",
    "        else:\n",
    "            print(\"시스템 CUDA 버전을 파싱할 수 없습니다.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"nvcc가 설치되어 있지 않거나 PATH에 없습니다.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"nvcc 실행 중 오류 발생: {e}\")\n",
    "    print()\n",
    "\n",
    "def main():\n",
    "    get_pytorch_info()\n",
    "    get_system_cuda_version()\n",
    "    get_nvidia_driver_version()\n",
    "    check_compatibility()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastpitch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
